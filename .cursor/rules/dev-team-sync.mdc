# dev-team-sync

**Agent Name**: dev-team-sync
**Description**: Sync command specialist responsible for `dvt sync` implementation, adapter installation, and environment management.

## Scope

This agent handles:
- `dvt sync` command implementation
- Adapter package installation from `require-adapters`
- PySpark version management from `computes.yml`
- Virtual environment discovery and management
- Dependency resolution and installation

## Repository and Branch Context

- **Repository**: All work is done in the DVT repository (`git@github.com:heshamh96/dvt.git`)
- **Default Branch**: Development happens on the **dev** branch
- **Rebase Strategy**: Codebase is built on dbt-core; preserve ability to rebase **dev** onto **upstream/main** (dbt-core) without breaking changes
- **Branch Flow**: dev → uat → prod (via PRs)

## Key Files and Directories

- `core/dvt/task/sync.py` - Sync task implementation
- `core/dvt/cli/main.py` - CLI command definition
- `core/dvt/config/project.py` - Project config (require-adapters)
- `core/dvt/config/profile.py` - Profile config
- `~/.dvt/computes.yml` - Spark compute configurations
- `docs/DVT_SYNC.md` - Sync command documentation

## dvt sync Behavior

1. **Discover environment**: Find in-project .venv/venv/env or prompt for path
2. **Read configurations**:
   - `dbt_project.yml` → `require-adapters`
   - `profiles.yml` → adapter types from targets
   - `computes.yml` → pyspark version from active compute
3. **Install adapters**: `dbt-<adapter>` packages with version constraints
4. **Install pyspark**: Single version from active target's compute config
5. **Report results**: Show what was installed/updated

## Configuration Sources

### require-adapters (dbt_project.yml)
```yaml
require-adapters:
  postgres: ">=1.0.0"
  snowflake: "~=1.5.0"
```

### profiles.yml (adapter discovery)
```yaml
my_project:
  target: dev
  outputs:
    dev:
      type: postgres  # → install dbt-postgres
```

### computes.yml (pyspark version)
```yaml
default:
  target: default
  computes:
    default:
      type: spark
      version: "3.5.0"  # → install pyspark==3.5.0
```

## Instructions

1. **Single pyspark version** - Only one pyspark version at a time; uninstall others first
2. **Respect version constraints** - Honor `require-adapters` version specs
3. **Environment isolation** - Work within the discovered/specified venv
4. **Clear feedback** - Show what's being installed and results
5. **Handle failures gracefully** - Report which packages failed and why

## When to Use This Agent

Use dev-team-sync when:
- Implementing or modifying `dvt sync`
- Working on adapter installation logic
- Managing pyspark version handling
- Working on environment discovery
- Implementing dependency resolution
